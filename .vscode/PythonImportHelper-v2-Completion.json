[
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "original_video",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "original_video = cv2.VideoCapture('original_output.avi')\nred_detected_video = cv2.VideoCapture('red_detected_output.avi')\nred_mask_video = cv2.VideoCapture('red_mask_output.avi')\n# Get frame dimensions and frame rate from one of the videos\nframe_width = int(original_video.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(original_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "red_detected_video",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "red_detected_video = cv2.VideoCapture('red_detected_output.avi')\nred_mask_video = cv2.VideoCapture('red_mask_output.avi')\n# Get frame dimensions and frame rate from one of the videos\nframe_width = int(original_video.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(original_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "red_mask_video",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "red_mask_video = cv2.VideoCapture('red_mask_output.avi')\n# Get frame dimensions and frame rate from one of the videos\nframe_width = int(original_video.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(original_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "frame_width",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "frame_width = int(original_video.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(original_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video\n    ret1, original_frame = original_video.read()\n    ret2, red_detected_frame = red_detected_video.read()",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "frame_height",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "frame_height = int(original_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video\n    ret1, original_frame = original_video.read()\n    ret2, red_detected_frame = red_detected_video.read()\n    ret3, red_mask_frame = red_mask_video.read()",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "fps",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "fps = original_video.get(cv2.CAP_PROP_FPS)\n# Create VideoWriter for the combined output video\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video\n    ret1, original_frame = original_video.read()\n    ret2, red_detected_frame = red_detected_video.read()\n    ret3, red_mask_frame = red_mask_video.read()\n    # If any video ends, stop the loop",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "fourcc",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "fourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video\n    ret1, original_frame = original_video.read()\n    ret2, red_detected_frame = red_detected_video.read()\n    ret3, red_mask_frame = red_mask_video.read()\n    # If any video ends, stop the loop\n    if not ret1 or not ret2 or not ret3:\n        break",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "output_video",
        "kind": 5,
        "importPath": "Color-detection-opencv.color_detection_opencv",
        "description": "Color-detection-opencv.color_detection_opencv",
        "peekOfCode": "output_video = cv2.VideoWriter('merged_output.avi', fourcc, fps, (frame_width * 3, frame_height))\nwhile True:\n    # Read frames from each video\n    ret1, original_frame = original_video.read()\n    ret2, red_detected_frame = red_detected_video.read()\n    ret3, red_mask_frame = red_mask_video.read()\n    # If any video ends, stop the loop\n    if not ret1 or not ret2 or not ret3:\n        break\n    # Convert red_mask_frame to a 3-channel image (BGR) to match the other frames",
        "detail": "Color-detection-opencv.color_detection_opencv",
        "documentation": {}
    },
    {
        "label": "get_limits",
        "kind": 2,
        "importPath": "Color-detection-opencv.utils",
        "description": "Color-detection-opencv.utils",
        "peekOfCode": "def get_limits(color):\n    c = np.uint8([[color]])  # BGR values\n    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n    hue = hsvC[0][0][0]  # Get the hue value\n    # Handle red hue wrap-around\n    if hue >= 165:  # Upper limit for divided red hue\n        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n        upperLimit = np.array([180, 255, 255], dtype=np.uint8)\n    elif hue <= 15:  # Lower limit for divided red hue\n        lowerLimit = np.array([0, 100, 100], dtype=np.uint8)",
        "detail": "Color-detection-opencv.utils",
        "documentation": {}
    },
    {
        "label": "face_cascade",
        "kind": 5,
        "importPath": "Face Detection.face_detection",
        "description": "Face Detection.face_detection",
        "peekOfCode": "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n# Read the input image\nimage = cv2.imread('input.jpg')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# Detect faces\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n# Draw rectangles around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n# Display the output",
        "detail": "Face Detection.face_detection",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 5,
        "importPath": "Face Detection.face_detection",
        "description": "Face Detection.face_detection",
        "peekOfCode": "image = cv2.imread('input.jpg')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# Detect faces\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n# Draw rectangles around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n# Display the output\ncv2.imshow('Face Detection', image)\ncv2.waitKey(0)",
        "detail": "Face Detection.face_detection",
        "documentation": {}
    },
    {
        "label": "gray",
        "kind": 5,
        "importPath": "Face Detection.face_detection",
        "description": "Face Detection.face_detection",
        "peekOfCode": "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# Detect faces\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n# Draw rectangles around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n# Display the output\ncv2.imshow('Face Detection', image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "Face Detection.face_detection",
        "documentation": {}
    },
    {
        "label": "faces",
        "kind": 5,
        "importPath": "Face Detection.face_detection",
        "description": "Face Detection.face_detection",
        "peekOfCode": "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n# Draw rectangles around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n# Display the output\ncv2.imshow('Face Detection', image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "Face Detection.face_detection",
        "documentation": {}
    }
]